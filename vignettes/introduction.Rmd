---
title: "Introduction to hydrorecipes"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to hydrorecipes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  dev = 'png',
  fig.width = 6,
  fig.asp = 0.8,
  out.width = "90%"
)
```


The **hydrorecipes** package aims to provide a few steps to improve the analysis of 
water level responses using relatively large datasets (millions of rows). It 
aims to work seamlessly within the tidymodels framework of packages.  While
the package was designed for water levels and pore-pressures, the *steps* may 
also be useful in to other fields of study.  While the examples in the 
introduction focus on barometric pressure and Earth tides, the *steps* can also 
be applied to precipitation and pumping responses.


```{r setup}
library(hydrorecipes)
data(transducer, package = "hydrorecipes")
head(transducer)
transducer$datetime_num <- as.numeric(transducer$datetime)
```

This data contains (~1.5 months) of timestamped water pressure, barometric 
pressure and synthetic Earth tide data with a 2 minute sampling frequency.
Our goal is to relate the water pressure data to the barometric, Earth tides 
in the presence of a background trend. We will look at a few different ways to 
analyze this dataset. For more information on the **recipes** package and 
**tidymodels** please see: https://recipes.tidymodels.org


To start with we will use the **recipes** package alone using a modified Toll
and Rasmussen, 2007 approach. We use logarithmically spaced lags instead of 
regularly spaced ones to improve computational performance and use the 
non-difference based approach.  *step_ns* is used to characterize the background
trend.

```{r}

rec_toll_rasmussen <- recipe(wl~baro+et+datetime_num, transducer) |>
  step_lag(baro, lag = log_lags(100, 86400 * 2 / 120)) |>
  step_lag(et, lag = seq(0, 180, 20)) |>
  step_ns(datetime_num, deg_free = 10) |>
  step_rm(baro) |>
  step_rm(et) |>
  prep()
input_toll_rasmussen <- rec_toll_rasmussen |> bake(new_data = NULL)

```

```{r}
fit_toll_rasmussen <- lm(wl~., input_toll_rasmussen) 

```

Next we will use the **recipes** package alone using a modified Rasmussen and 
Mote, 2007 approach. We use logarithmically spaced lags instead of 
regularly spaced ones to improve computational performance and use the 
non-difference based approach.  *step_ns* is used to characterize the background
trend.

```{r}
tidal_freqs <- c(0.89324406, 0.92953571, 0.96644626, 1.00273791, 1.03902956, 
                 1.07594011, 1.86454723, 1.89598197, 1.93227362, 1.96856526, 
                 2.00000000, 2.89841042)
rec_rasmussen_mote <- recipe(wl~baro+datetime_num, transducer) |>
  step_lag(baro, lag = log_lags(100, 86400 * 2 / 120)) |>
  step_harmonic(datetime_num,
                frequency = tidal_freqs,
                cycle_size = 86400,
                keep_original_cols = TRUE) |>
  step_ns(datetime_num, deg_free = 10) |>
  step_rm(baro) |>
  prep()
input_rasmussen_mote <- rec_rasmussen_mote |> bake(new_data = NULL)

```

```{r}
fit_rasmussen_mote <- lm(wl~., input_rasmussen_mote) 
```

This is the method of Kennel 2020 which uses a distributed lag model and the **earthtide** package to generate synthetic wave groups.

```{r}
wave_groups <- earthtide::eterna_wavegroups
wave_groups <- na.omit(wave_groups[wave_groups$time == '1 month', ])
wave_groups <- wave_groups[wave_groups$start > 0.5,]
latitude  <- 34.23411
longitude <- -118.678
elevation <- 500
cutoff    <- 1e-7
catalog   <- 'ksm04'
method    <- 'volume_strain'
rec_kennel <- recipe(wl~baro+datetime_num, transducer) |>
  step_distributed_lag(baro, knots = log_lags(15, 86400 * 2 / 120)) |>
  step_earthtide(datetime_num,
                 latitude = latitude,
                 longitude = longitude,
                 elevation = elevation,
                 cutoff = cutoff,
                 method = method,
                 catalog = catalog,
                 astro_update = 1,
                 wave_groups = wave_groups) |>
  step_ns(datetime_num, deg_free = 10) |>
  step_rm(baro) |>
  prep()

input_kennel <- rec_kennel |> bake(new_data = NULL)
```

```{r}
fit_kennel <- lm(wl~., input_kennel) 
```

We can compare the three models and they give similar results.  The distributed lag version is particularly suited to long lag times and large datasets (small sampling interval). *step_earthtide* allows for easily estimating phase shifts unlike *step_harmonic* and the lagged version.

```{r results = 'asis'}

model_results <- rbind(broom::glance(fit_kennel),
                       broom::glance(fit_toll_rasmussen),
                       broom::glance(fit_rasmussen_mote)
)
model_results$name <- c('kennel_2020',
                        'toll_rasmussen_2007',
                        'rasmussen_mote_2007'
)
knitr::kable(model_results[,c('name', 'r.squared', 'sigma', 'AIC', 'BIC', 'df.residual', 'nobs')])
```
The **hydrorecipes** package also has a few methods to helper methods to examine
the response functions and decomposition.  

```{r}
resp_kennel <- response(fit = fit_kennel, rec = rec_kennel)

# run an lm model with the rec_kennel recipe and the transducer dataset
result      <- run_lm(rec_kennel, new_data = transducer, outcome_column = 'wl')
names(result)
```

To get a quick plot of the responses you can use *plot_response*.  These are meant to provide a quick look and are not for flexible enough polished figures. *plot_response* returns a list of *ggplot* objects.

``` {r out.width = '45%'}
str(result$response)
p <- plot_response(result)
a <- lapply(p, print)
```

Next we can analyze the decomposition. *plot_components* returns a single 
facetted ggplot object.

```{r}

plot_components(result, 
                x_axis_column = 'datetime',
                plot_columns = c(
                  'wl',
                  'predicted',
                  'distributed_lag_baro',
                  'earthtide_datetime_num'
                ))

```

